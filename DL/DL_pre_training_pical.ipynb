{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch, DataLoader\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.utils import set_determinism\n",
    "\n",
    "print_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = os.environ.get(\"/home/yfang/MRI_95_result\")#存模型权重和结果的文件夹\n",
    "data_dir='dataset/MRI_95_merge'#存数据的文件夹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设定随机种子\n",
    "set_determinism(seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对图片的数量，图片的大小，标签，图片的数量进行可视化\n",
    "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [os.path.join(data_dir, class_names[i], x) for x in os.listdir(os.path.join(data_dir, class_names[i]))]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机挑选九张图片进行可视化\n",
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i, k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = PIL.Image.open(image_files_list[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_class[k]])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#划分数据集\n",
    "val_frac = 0.1\n",
    "test_frac = 0.1\n",
    "length = len(image_files_list)\n",
    "indices = np.arange(length)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "test_split = int(test_frac * length)\n",
    "val_split = int(val_frac * length) + test_split\n",
    "test_indices = indices[:test_split]\n",
    "val_indices = indices[test_split:val_split]\n",
    "train_indices = indices[val_split:]\n",
    "\n",
    "train_x = [image_files_list[i] for i in train_indices]\n",
    "train_y = [image_class[i] for i in train_indices]\n",
    "val_x = [image_files_list[i] for i in val_indices]\n",
    "val_y = [image_class[i] for i in val_indices]\n",
    "test_x = [image_files_list[i] for i in test_indices]\n",
    "test_y = [image_class[i] for i in test_indices]\n",
    "\n",
    "print(f\"Training count: {len(train_x)}, Validation count: \" f\"{len(val_x)}, Test count: {len(test_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据增强，归一化，随机旋转，随机翻转，随机缩放。\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        EnsureChannelFirst(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
    "\n",
    "y_pred_trans = Compose([Activations(softmax=True)])\n",
    "y_trans = Compose([AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建dataloader\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=12)\n",
    "\n",
    "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
    "val_loader = DataLoader(val_ds, batch_size=16, num_workers=12)\n",
    "\n",
    "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=16, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建模型\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "model = timm.create_model('efficientnetv2_s', pretrained=False)\n",
    "in_features = model.classifier.in_features\n",
    "model.classifier = nn.Linear(in_features, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建损失和优化器\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "# model = DenseNet121(spatial_dims=2, in_channels=3, out_channels=num_class).to(device)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-5)\n",
    "max_epochs = 200\n",
    "val_interval = 1\n",
    "auc_metric = ROCAUCMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建训练和验证过程\n",
    "best_metric = -1\n",
    "best_metric_epoch = -1\n",
    "train_loss_values = []\n",
    "train_acc_values =[]\n",
    "train_auc_values=[]\n",
    "val_loss_values=[]\n",
    "val_acc_values=[]\n",
    "val_auc_values = []\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print(\"-\" * 10)\n",
    "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    step = 0\n",
    "    train_y_pred = torch.tensor([], dtype=torch.float32, device='cpu')\n",
    "    train_y = torch.tensor([], dtype=torch.long, device='cpu')\n",
    "    for batch_data in train_loader:\n",
    "        step += 1\n",
    "        inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        train_y_pred = torch.cat([train_y_pred, outputs.cpu()], dim=0)\n",
    "        train_y = torch.cat([train_y, labels.cpu()], dim=0)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
    "        epoch_len = len(train_ds) // train_loader.batch_size\n",
    "    y_onehot = [y_trans(i) for i in decollate_batch(train_y, detach=False)]\n",
    "    y_pred_act = [y_pred_trans(i) for i in decollate_batch(train_y_pred)]\n",
    "    auc_metric(y_pred_act, y_onehot)\n",
    "    train_auc = auc_metric.aggregate()\n",
    "    auc_metric.reset()\n",
    "    train_auc_values.append(train_auc)\n",
    "    del y_pred_act, y_onehot\n",
    "    acc_value = torch.eq(train_y_pred.argmax(dim=1), train_y)\n",
    "    train_acc = acc_value.sum().item() / len(acc_value)\n",
    "    train_acc_values.append(train_acc)\n",
    "    train_loss /= step\n",
    "    train_loss_values.append(train_loss)\n",
    "    print(f\"epoch {epoch + 1} average loss: {train_loss:.4f}\")\n",
    "    \n",
    "\n",
    "    if (epoch + 1) % val_interval == 0:\n",
    "        model.eval()\n",
    "        val_loss=0\n",
    "        val_step=0\n",
    "        with torch.no_grad():\n",
    "            val_y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "            val_y = torch.tensor([], dtype=torch.long, device=device)\n",
    "            for val_data in val_loader:\n",
    "                val_step += 1\n",
    "                val_images, val_labels = (\n",
    "                    val_data[0].to(device),\n",
    "                    val_data[1].to(device),\n",
    "                )\n",
    "                val_outputs=model(val_images)\n",
    "                val_y_pred = torch.cat([val_y_pred, val_outputs], dim=0)\n",
    "                val_y = torch.cat([val_y, val_labels], dim=0)\n",
    "                loss = loss_function(val_outputs, val_labels)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= val_step\n",
    "            val_loss_values.append(val_loss)\n",
    "            y_onehot = [y_trans(i) for i in decollate_batch(val_y, detach=False)]\n",
    "            y_pred_act = [y_pred_trans(i) for i in decollate_batch(val_y_pred)]\n",
    "            auc_metric(y_pred_act, y_onehot)\n",
    "            val_auc = auc_metric.aggregate()\n",
    "            auc_metric.reset()\n",
    "            del y_pred_act, y_onehot\n",
    "            val_auc_values.append(val_auc)\n",
    "            acc_value = torch.eq(val_y_pred.argmax(dim=1), val_y)\n",
    "            val_acc = acc_value.sum().item() / len(acc_value)\n",
    "            val_acc_values.append(val_acc)\n",
    "            if val_auc > best_metric:\n",
    "                best_metric = val_auc\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), os.path.join(root_dir, \"efficientv2_l_best_metric_model.pth\"))\n",
    "                print(\"saved new best metric model\")\n",
    "    print(\n",
    "        f\"current epoch: {epoch + 1}\"\n",
    "        f\" train AUC: {train_auc:.4f} \" \n",
    "        f\" train loss: {train_loss:.4f}\"\n",
    "        f\" train accuracy: {train_acc:.4f}\"\n",
    "        f\" val AUC: {val_auc:.4f} \" \n",
    "        f\" val loss: {val_loss:.4f}\"\n",
    "        f\" val accuracy: {val_acc:.4f}\"\n",
    "        f\" best AUC: {best_metric:.4f}\"\n",
    "        f\" at epoch: {best_metric_epoch}\"\n",
    "    )\n",
    "\n",
    "print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对loss,acc,auc进行可视化\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(train_loss_values, label='train loss')\n",
    "plt.plot(val_loss_values, label='val loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\" loss\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(train_acc_values, label='train acc')\n",
    "plt.plot(val_acc_values, label='val acc')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\" acc\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(train_auc_values, label='train auc')\n",
    "plt.plot(val_auc_values, label='val auc')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\" auc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#对测试集进行测试\n",
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"efficientv2_s_best_metric_model.pth\"), map_location='cpu'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "    y = torch.tensor([], dtype=torch.long, device=device)\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = model(test_images)\n",
    "        y_pred = torch.cat([y_pred, pred], dim=0)\n",
    "        y = torch.cat([y, test_labels], dim=0)\n",
    "        # for i in range(len(pred)):\n",
    "        #     y_true.append(test_labels[i].item())\n",
    "        #     y_pred.append(pred[i].item())\n",
    "    y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
    "    y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "    auc_metric(y_pred_act, y_onehot)\n",
    "    result = auc_metric.aggregate()\n",
    "    auc_metric.reset()\n",
    "    del y_pred_act, y_onehot\n",
    "    acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "    print(len(acc_value))\n",
    "    test_acc = acc_value.sum().item() / len(acc_value)\n",
    "    print('test acc:',test_acc)\n",
    "    print('test auc:',result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jmseg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
