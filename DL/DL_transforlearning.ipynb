{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from monai.apps import download_and_extract\n",
    "from monai.config import print_config\n",
    "from monai.data import decollate_batch, DataLoader\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.networks.nets import DenseNet121\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    EnsureChannelFirst,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    LoadImage,\n",
    "    RandFlip,\n",
    "    RandRotate,\n",
    "    RandZoom,\n",
    "    ScaleIntensity,\n",
    ")\n",
    "from monai.utils import set_determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/home/yfang/MRI_110_result\"\n",
    "#模型训练时设置随机种子\n",
    "set_determinism(seed=0)\n",
    "data_dir='dataset/MRI_110_merge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
    "num_class = len(class_names)\n",
    "image_files = [\n",
    "    [os.path.join(data_dir, class_names[i], x) for x in os.listdir(os.path.join(data_dir, class_names[i]))]\n",
    "    for i in range(num_class)\n",
    "]\n",
    "num_each = [len(image_files[i]) for i in range(num_class)]\n",
    "image_files_list = []\n",
    "image_class = []\n",
    "for i in range(num_class):\n",
    "    image_files_list.extend(image_files[i])\n",
    "    image_class.extend([i] * num_each[i])\n",
    "num_total = len(image_class)\n",
    "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
    "\n",
    "print(f\"Total image count: {num_total}\")\n",
    "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
    "print(f\"Label names: {class_names}\")\n",
    "print(f\"Label counts: {num_each}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机取九张图进行一个可视化\n",
    "plt.subplots(3, 3, figsize=(8, 8))\n",
    "for i, k in enumerate(np.random.randint(num_total, size=9)):\n",
    "    im = PIL.Image.open(image_files_list[k])\n",
    "    arr = np.array(im)\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.xlabel(class_names[image_class[k]])\n",
    "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据临床取的训练集和测试集进行数据划分\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "import shutil\n",
    "import tempfile\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "# train_frac = 0.8\n",
    "# test_frac = 0.2\n",
    "# 读取三个Excel文件\n",
    "train_df = pd.read_excel(r'/home/yfang/prostate/clinical/data/clinic_blood_110_train(1).xlsx')\n",
    "test_df = pd.read_excel(r'/home/yfang/prostate/clinical/data/clinic_blood_110_test(1).xlsx')\n",
    "df = pd.read_excel(r'/home/yfang/prostate/clinical/data/name_number.xlsx')\n",
    "\n",
    "new_column_names = {'姓名': 'name'}\n",
    "train_df = train_df.rename(columns=new_column_names)\n",
    "test_df = test_df.rename(columns=new_column_names)\n",
    "# 使用merge函数进行拼接\n",
    "# 以df1和df2的column_name列为键进行拼接\n",
    "train_df = pd.merge(train_df, df, on='name',how='inner')\n",
    "test_df = pd.merge(test_df, df, on='name',how='inner')\n",
    "\n",
    "train_value = train_df['Value']\n",
    "test_value = test_df['Value']\n",
    "\n",
    "length = len(image_files_list)\n",
    "indices = np.arange(length)\n",
    "train_indices =  []\n",
    "test_indices = []\n",
    "\n",
    "for index, img_path in zip (indices,image_files_list):\n",
    "\n",
    "    if int(os.path.basename(image_files_list[index]).split('_')[0]) in train_value.tolist():\n",
    "        # print(\"*****\")\n",
    "        train_indices.append(index)\n",
    "    elif int(os.path.basename(image_files_list[index]).split('_')[0]) in test_value.tolist():\n",
    "        test_indices.append(index)\n",
    "   \n",
    "\n",
    "print(train_indices)\n",
    "print(test_indices)\n",
    "\n",
    "train_xx = [image_files_list[i] for i in train_indices]\n",
    "train_yy = [image_class[i] for i in train_indices]\n",
    "\n",
    "test_xx = [image_files_list[i] for i in test_indices]\n",
    "test_yy = [image_class[i] for i in test_indices]\n",
    "\n",
    "print(f\"Training count: {len(train_xx)},  Test count: {len(test_xx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = Compose(\n",
    "    [\n",
    "        LoadImage(image_only=True),\n",
    "        EnsureChannelFirst(),\n",
    "        ScaleIntensity(),\n",
    "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
    "        RandFlip(spatial_axis=0, prob=0.5),\n",
    "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
    "\n",
    "y_pred_trans = Compose([Activations(softmax=True)])\n",
    "y_trans = Compose([AsDiscrete(to_onehot=num_class)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义class初始化数据集：MedNISTDataset（可修改name）\n",
    "class MedNISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_files, labels, transforms): \n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.transforms(self.image_files[index]), self.labels[index]\n",
    "\n",
    "\n",
    "# train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
    "# train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=12)\n",
    "\n",
    "\n",
    "test_ds = MedNISTDataset(test_xx, test_yy, val_transforms)\n",
    "test_loader = DataLoader(test_ds, batch_size=16, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "def get_model():\n",
    "    model = timm.create_model('efficientnetv2_s', pretrained=False)\n",
    "    in_features = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(in_features, 2)\n",
    "    model_weight_path = \"/home/yfang/result/efficientv2_s_best_metric_model.pth\"\n",
    "    assert os.path.exists(model_weight_path), \"file {} does not exist.\".format(model_weight_path)\n",
    "    model.load_state_dict(torch.load(model_weight_path, map_location=device))\n",
    "    in_channel = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(in_channel, 3)\n",
    "    model.to(device)\n",
    "    return model\n",
    "model = get_model()\n",
    "loss_function = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from torch.utils.data import DataLoader\n",
    "#保存跑的结果列表到excel中\n",
    "import pandas as pd\n",
    "# 使用stratifiedKFold进行交叉验证\\\n",
    "n_splits= 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2023)\n",
    "for fold, (train_indices, val_indices) in enumerate(skf.split(train_xx, train_yy)):\n",
    "    if model:\n",
    "        del model\n",
    "    model = get_model()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)\n",
    "    print(f\"Fold {fold + 1}/{n_splits}\")#根据fold的划分获取训练集和验证集\n",
    "    train_x_fold = [image_files_list[i] for i in train_indices]\n",
    "    train_y_fold = [image_class[i] for i in train_indices]\n",
    "    val_x_fold = [image_files_list[i] for i in val_indices]\n",
    "    val_y_fold = [image_class[i] for i in val_indices]\n",
    "\n",
    "    train_ds = MedNISTDataset(train_x_fold, train_y_fold, train_transforms)\n",
    "    train_loader = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=12)\n",
    "    val_ds = MedNISTDataset(val_x_fold, val_y_fold, val_transforms)\n",
    "    val_loader = DataLoader(val_ds, batch_size=16,num_workers=12)\n",
    "    max_epochs = 200\n",
    "    val_interval = 1\n",
    "    auc_metric = ROCAUCMetric()\n",
    "    best_metric = -1\n",
    "    best_metric_epoch = -1\n",
    "    train_loss_values = []\n",
    "    train_acc_values = []\n",
    "    train_auc_values=[]\n",
    "    val_loss_values=[]\n",
    "    val_acc_values=[]\n",
    "    val_auc_values = []\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        step = 0\n",
    "        train_y_pred = torch.tensor([], dtype=torch.float32, device='cpu')\n",
    "        train_y = torch.tensor([], dtype=torch.long, device='cpu')\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            train_y_pred = torch.cat([train_y_pred, outputs.cpu()], dim=0)\n",
    "            train_y = torch.cat([train_y, labels.cpu()], dim=0)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            print(f\"{step}/{len(train_ds) // train_loader.batch_size}, \" f\"train_loss: {loss.item():.4f}\")\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "        y_onehot = [y_trans(i) for i in decollate_batch(train_y, detach=False)]\n",
    "        y_pred_act = [y_pred_trans(i) for i in decollate_batch(train_y_pred)]\n",
    "        auc_metric(y_pred_act, y_onehot)\n",
    "        train_auc = auc_metric.aggregate()\n",
    "        auc_metric.reset()\n",
    "        train_auc_values.append(train_auc)\n",
    "        del y_pred_act, y_onehot\n",
    "        acc_value = torch.eq(train_y_pred.argmax(dim=1), train_y)\n",
    "        train_acc = acc_value.sum().item() / len(acc_value)\n",
    "        train_acc_values.append(train_acc)\n",
    "        train_loss /= step\n",
    "        train_loss_values.append(train_loss)\n",
    "        print(f\"epoch {epoch + 1} average loss: {train_loss:.4f}\")\n",
    "        #验证集\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            val_loss=0\n",
    "            val_step=0\n",
    "            with torch.no_grad():\n",
    "                val_y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "                val_y = torch.tensor([], dtype=torch.long, device=device)\n",
    "                for val_data in val_loader:\n",
    "                    val_step += 1\n",
    "                    val_images, val_labels = (\n",
    "                        val_data[0].to(device),\n",
    "                        val_data[1].to(device),\n",
    "                    )\n",
    "                    val_outputs=model(val_images)\n",
    "                    val_y_pred = torch.cat([val_y_pred, val_outputs], dim=0)\n",
    "                    val_y = torch.cat([val_y, val_labels], dim=0)\n",
    "                    loss = loss_function(val_outputs, val_labels)\n",
    "                    val_loss += loss.item()\n",
    "                val_loss /= val_step\n",
    "                val_loss_values.append(val_loss)\n",
    "                y_onehot = [y_trans(i) for i in decollate_batch(val_y, detach=False)]\n",
    "                y_pred_act = [y_pred_trans(i) for i in decollate_batch(val_y_pred)]\n",
    "                auc_metric(y_pred_act, y_onehot)\n",
    "                val_auc = auc_metric.aggregate()\n",
    "                auc_metric.reset()\n",
    "                del y_pred_act, y_onehot\n",
    "                val_auc_values.append(val_auc)\n",
    "                acc_value = torch.eq(val_y_pred.argmax(dim=1), val_y)\n",
    "                val_acc = acc_value.sum().item() / len(acc_value)\n",
    "                val_acc_values.append(val_acc)\n",
    "                if val_auc > best_metric:\n",
    "                    best_metric = val_auc\n",
    "                    best_metric_epoch = epoch + 1\n",
    "                    torch.save(model.state_dict(), os.path.join(root_dir, \"{}mri_110_efficientv2_s_best_metric_model.pth\".format(fold+1)))\n",
    "                    print(\"saved new best metric model\")\n",
    "        print(\n",
    "            f\"fold: {fold + 1}\"\n",
    "            f\"current epoch: {epoch + 1}\"\n",
    "            f\" train AUC: {train_auc:.4f} \" \n",
    "            f\" train loss: {train_loss:.4f}\"\n",
    "            f\" train accuracy: {train_acc:.4f}\"\n",
    "            f\" val AUC: {val_auc:.4f} \" \n",
    "            f\" val loss: {val_loss:.4f}\"\n",
    "            f\" val accuracy: {val_acc:.4f}\"\n",
    "            f\" best AUC: {best_metric:.4f}\"\n",
    "            f\" at epoch: {best_metric_epoch}\"\n",
    "        )\n",
    "\n",
    "    print(f\"train completed, best_metric: {best_metric:.4f} \" f\"at epoch: {best_metric_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(train_loss_values, label='train loss')\n",
    "plt.plot(val_loss_values, label='val loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\" loss\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(train_acc_values, label='train acc')\n",
    "plt.plot(val_acc_values, label='val acc')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\" acc\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(train_auc_values, label='train auc')\n",
    "plt.plot(val_auc_values, label='val auc')\n",
    "plt.legend(loc='upper left')\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.title(\" auc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(root_dir, \"1mri_95_efficientv2_s_best_metric_model.pth\"), map_location='cpu'))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    y_pred = torch.tensor([], dtype=torch.float32, device=device)\n",
    "    y = torch.tensor([], dtype=torch.long, device=device)\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = (\n",
    "            test_data[0].to(device),\n",
    "            test_data[1].to(device),\n",
    "        )\n",
    "        pred = model(test_images)\n",
    "        y_pred = torch.cat([y_pred, pred], dim=0)\n",
    "        y = torch.cat([y, test_labels], dim=0)\n",
    "        # for i in range(len(pred)):\n",
    "        #     y_true.append(test_labels[i].item())\n",
    "        #     y_pred.append(pred[i].item())\n",
    "    y_onehot = [y_trans(i) for i in decollate_batch(y, detach=False)]\n",
    "    y_pred_act = [y_pred_trans(i) for i in decollate_batch(y_pred)]\n",
    "    pred_lables = [max(y_pred[i]) for i in range(len(y_pred))]\n",
    "    print(pred_lables)\n",
    "    auc_metric(y_pred_act, y_onehot)\n",
    "    result = auc_metric.aggregate()\n",
    "    auc_metric.reset()\n",
    "    del y_pred_act, y_onehot\n",
    "    acc_value = torch.eq(y_pred.argmax(dim=1), y)\n",
    "    print(len(acc_value))\n",
    "    test_acc = acc_value.sum().item() / len(acc_value)\n",
    "    print('test acc:',test_acc)\n",
    "    print('test auc:',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#提取深度学习特征\n",
    "# 将列表中的张量转换为 NumPy 数组\n",
    "numpy_array_list = [tensor.cpu().numpy() for tensor in pred_lables]\n",
    "name = [os.path.basename(i).split(\".\")[0] for i in test_xx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#保存跑的结果列表到excel中\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# 创建一个DataFrame\n",
    "data = {'number': name,\n",
    "        'label': test_yy,\n",
    "        'pred': numpy_array_list\n",
    "    }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_excel('./MRI_110_result/DL_result.xlsx',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#每个患者选取的两张图片预测值进行平均求和\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = r'/home/yfang/MRI_110_result/DL_result.xlsx'\n",
    "\n",
    "path1 = r'/home/yfang/MRI_110_result/data_110.xlsx'\n",
    "df1 = pd.read_excel(path1)\n",
    "df1\n",
    "# df1 = df1[\"Value\"]\n",
    "\n",
    "df = pd.read_excel(path)\n",
    "list1 = []\n",
    "\n",
    "df2 = pd.DataFrame()\n",
    "\n",
    "a = (df[df['number']== '60011088833_2']['pred'].values + df[df['number']== '60011088833_1']['pred'].values)/2\n",
    "a[0]\n",
    "for i in df1['Value']:\n",
    "    for j in df['number']:\n",
    "        if str(i) == j.split('_')[0]:\n",
    "            a = (df[df['number']== str(i) + '_2']['pred'].values + df[df['number']== str(i) + '_1']['pred'].values)/2\n",
    "            df2 = df2._append(pd.DataFrame({'pred':[a[0]], 'name': [str(i)]},index=[0]),ignore_index=True)\n",
    "            \n",
    "            break\n",
    "df2\n",
    "df2.to_excel(r'/home/yfang/MRI_110_result/DL_pred_lable_value.xlsx')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
